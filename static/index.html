<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Voice Agent</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            background-color: #1a1b26;
            color: white;
            margin: 0;
            padding: 20px;
            display: flex;
            flex-direction: column;
            align-items: center;
        }

        .container {
            width: 100%;
            max-width: 800px;
            border: 3px double rgb(91, 164, 91);
            border-radius: 10px;
            padding: 20px;
            box-sizing: border-box;
        }

        .header {
            text-align: center;
            margin-bottom: 20px;
        }

        .status-indicator {
            background-color: #2a2b36;
            border: 1px solid rgb(91, 164, 91);
            border-radius: 5px;
            padding: 10px;
            text-align: center;
            margin-bottom: 20px;
        }

        .log-container {
            height: 400px;
            border: 2px solid rgb(205, 133, 63);
            border-radius: 10px;
            padding: 15px;
            overflow-y: auto;
            background-color: #2a2b36;
            white-space: pre-wrap;
        }

        button {
            background-color: rgb(91, 164, 91);
            color: white;
            border: none;
            padding: 10px 20px;
            margin: 10px 0;
            border-radius: 5px;
            cursor: pointer;
            font-weight: bold;
        }

        button:hover {
            background-color: rgb(71, 134, 71);
        }

        button:disabled {
            background-color: #555;
            cursor: not-allowed;
        }

        .error-banner {
            background-color: #ff5252;
            color: white;
            padding: 10px;
            margin-bottom: 20px;
            border-radius: 5px;
            text-align: center;
        }

        .volume-meter {
            height: 10px;
            background-color: #333;
            border-radius: 5px;
            margin: 10px 0;
            overflow: hidden;
        }

        .volume-level {
            height: 100%;
            width: 0%;
            background-color: rgb(91, 164, 91);
            transition: width 0.1s;
        }

        .status-text {
            font-size: 0.9em;
            margin-top: 5px;
            color: #aaa;
        }
    </style>
</head>

<body>
    <div class="container">
        <div id="errorBanner" class="error-banner" style="display: none;"></div>
        <div class="header">
            <h1>Voice Agent</h1>
            <p>Speak to the agent. When you stop speaking, it will respond.</p>
        </div>

        <div class="status-indicator" id="statusIndicator">
            âšª Press Start Recording to begin
        </div>

        <div class="volume-meter">
            <div class="volume-level" id="volumeLevel"></div>
        </div>
        <div class="status-text" id="statusText">Silence detection ready</div>

        <div class="controls">
            <button id="recordButton">Start Recording</button>
        </div>

        <div class="log-container" id="logContainer"></div>
    </div>

    <script>
        let socket;
        let isRecording = false;
        let mediaRecorder;
        let audioContext;
        let audioQueue = [];
        let audioPlayer = new Audio();
        let isPlayingAudio = false;

        const recordButton = document.getElementById('recordButton');
        const statusIndicator = document.getElementById('statusIndicator');
        const logContainer = document.getElementById('logContainer');
        const errorBanner = document.getElementById('errorBanner');
        const volumeLevel = document.getElementById('volumeLevel');
        const statusText = document.getElementById('statusText');

        // Silence detection settings
        const SILENCE_THRESHOLD = 0.01; // Adjust based on testing (0-1)
        const SILENCE_DURATION = 1500; // milliseconds of silence to trigger processing
        let isSilent = false;
        let silenceStart = 0;
        let volumeAverage = 0;
        let silenceDetectionActive = false;
        let isProcessing = false;
        let processingTimeout = null;

        // Check if the browser supports required APIs
        function checkBrowserSupport() {
            let errorMessages = [];

            // Check for secure context
            if (!window.isSecureContext) {
                errorMessages.push("This page must be accessed over HTTPS to use the microphone.");
            }

            // Check for MediaDevices API
            if (!navigator.mediaDevices || !navigator.mediaDevices.getUserMedia) {
                errorMessages.push("Your browser doesn't support the MediaDevices API required for microphone access.");
            }

            // Check for AudioContext
            if (typeof AudioContext === 'undefined' && typeof webkitAudioContext === 'undefined') {
                errorMessages.push("Your browser doesn't support the Web Audio API.");
            }

            // Check for WebSockets
            if (typeof WebSocket === 'undefined') {
                errorMessages.push("Your browser doesn't support WebSockets.");
            }

            if (errorMessages.length > 0) {
                showError(errorMessages.join("<br>"));
                return false;
            }

            return true;
        }

        // Show error banner
        function showError(message) {
            errorBanner.innerHTML = message;
            errorBanner.style.display = 'block';
        }

        // Initialize WebSocket connection
        function connectWebSocket() {
            const protocol = window.location.protocol === 'https:' ? 'wss:' : 'ws:';
            const wsUrl = `${protocol}//${window.location.host}/ws`;

            log(`Connecting to WebSocket: ${wsUrl}`);

            socket = new WebSocket(wsUrl);

            socket.onopen = function (e) {
                log('Connected to server');
            };

            socket.onmessage = async function (event) {
                if (event.data instanceof Blob) {
                    // Handle audio data
                    const audioData = await event.data.arrayBuffer();
                    // Add to queue instead of playing immediately
                    queueAudio(audioData);
                } else {
                    // Handle text messages
                    try {
                        const data = JSON.parse(event.data);
                        if (data.type === 'transcription') {
                            log(`User: ${data.text}\n\n`);
                        }
                        else if (data.type === 'agent_response') {
                            log(`Agent: ${data.text}\n\n`);
                        } else if (data.type === 'lifecycle') {
                            log(`Lifecycle event: ${data.event}`);

                            // Restart listening when done processing
                            if (data.event === 'completed' && isProcessing) {
                                restartListening();
                            }
                        } else if (data.type === 'error') {
                            log(`Error: ${data.message}`);
                            restartListening();
                        } else if (data.type === 'processing_complete') {
                            restartListening();
                        }
                    } catch (e) {
                        log(`Received message: ${event.data}\n\n`);
                    }
                }
            };

            socket.onclose = function (event) {
                if (event.wasClean) {
                    log(`Connection closed cleanly, code=${event.code} reason=${event.reason}`);
                } else {
                    log('Connection died');
                }

                // Try to reconnect after 3 seconds
                setTimeout(connectWebSocket, 3000);
            };

            socket.onerror = function (error) {
                log(`WebSocket Error: ${error.message}`);
            };
        }

        // Log messages to UI
        function log(message) {
            const entry = document.createElement('div');
            entry.textContent = message;
            logContainer.appendChild(entry);
            logContainer.scrollTop = logContainer.scrollHeight;
        }

        // Handle recording button click
        recordButton.addEventListener('click', function () {
            if (!isRecording) {
                startRecording();
            } else {
                stopRecording();
            }
        });

        // Start recording microphone audio
        async function startRecording() {
            try {
                // If we're not in a secure context, show a helpful message
                if (!window.isSecureContext) {
                    showError(`
                        Microphone access requires a secure context (HTTPS). 
                        <br>For local development, try:
                        <br>â€¢ Using localhost instead of 127.0.0.1
                        <br>â€¢ Running with a local SSL certificate
                        <br>â€¢ Using a tool like ngrok to create a secure tunnel
                    `);
                    return;
                }

                // Ensure MediaDevices API is available
                if (!navigator.mediaDevices || !navigator.mediaDevices.getUserMedia) {
                    showError("Your browser doesn't support microphone access. Try using Chrome, Firefox, or Edge.");
                    return;
                }

                const stream = await navigator.mediaDevices.getUserMedia({ audio: true });

                // Use appropriate AudioContext constructor based on browser
                const AudioContextClass = window.AudioContext || window.webkitAudioContext;
                audioContext = new AudioContextClass({
                    sampleRate: 24000
                });

                // For older browsers that don't support constructor options
                if (audioContext.sampleRate !== 24000) {
                    log(`Note: Using browser's sample rate: ${audioContext.sampleRate}Hz instead of 24000Hz`);
                }

                const source = audioContext.createMediaStreamSource(stream);

                // Create analyzer for volume detection
                const analyser = audioContext.createAnalyser();
                analyser.fftSize = 256;
                analyser.smoothingTimeConstant = 0.3;
                source.connect(analyser);

                // Setup processing
                const processor = audioContext.createScriptProcessor(2048, 1, 1);
                source.connect(processor);
                processor.connect(audioContext.destination);

                // Setup silence detection with analyzer
                const dataArray = new Uint8Array(analyser.frequencyBinCount);

                // Process audio data and detect silence
                processor.onaudioprocess = function (e) {
                    if (!isRecording) return;

                    // Get audio data
                    const inputData = e.inputBuffer.getChannelData(0);
                    const audioData = convertFloat32ToInt16(inputData);

                    // Send audio to server
                    if (socket && socket.readyState === WebSocket.OPEN && !isProcessing) {
                        socket.send(audioData);
                    }

                    // Volume analysis for silence detection
                    analyser.getByteFrequencyData(dataArray);

                    // Calculate volume level (0-1)
                    let sum = 0;
                    for (let i = 0; i < dataArray.length; i++) {
                        sum += dataArray[i];
                    }

                    const average = sum / dataArray.length / 255;
                    volumeAverage = average * 0.3 + volumeAverage * 0.7; // Smooth the value

                    // Update volume meter visualization
                    volumeLevel.style.width = (volumeAverage * 100) + '%';

                    // Silence detection
                    if (silenceDetectionActive && !isProcessing) {
                        if (volumeAverage < SILENCE_THRESHOLD) {
                            if (!isSilent) {
                                isSilent = true;
                                silenceStart = Date.now();
                                statusText.textContent = "Silence detected...";
                            } else if (Date.now() - silenceStart > SILENCE_DURATION) {
                                // Silence duration exceeded threshold - process the audio
                                processAudio();
                            }
                        } else {
                            if (isSilent) {
                                isSilent = false;
                                statusText.textContent = "Speaking...";
                            }
                        }
                    }
                };

                mediaRecorder = {
                    stream: stream,
                    source: source,
                    analyser: analyser,
                    processor: processor,
                    stop: function () {
                        this.source.disconnect();
                        this.analyser.disconnect();
                        this.processor.disconnect();
                        this.stream.getTracks().forEach(track => track.stop());
                    }
                };

                isRecording = true;
                silenceDetectionActive = true;
                isSilent = false;
                isProcessing = false;
                recordButton.textContent = 'Stop Recording';
                statusIndicator.textContent = 'ðŸ”´ Recording... (Will auto-process on silence)';
                statusText.textContent = "Speak now...";
                log('Recording started with silence detection');

                // Clear any pending audio when starting a new recording
                audioQueue = [];
                isPlayingAudio = false;

            } catch (err) {
                log(`Error accessing microphone: ${err.message}`);
                console.error('Microphone error:', err);

                if (err.name === 'NotAllowedError' || err.name === 'PermissionDeniedError') {
                    showError("Microphone access was denied. Please allow microphone access in your browser settings.");
                } else if (err.name === 'NotFoundError' || err.name === 'DevicesNotFoundError') {
                    showError("No microphone was found. Please connect a microphone and try again.");
                } else {
                    showError(`Microphone error: ${err.message}`);
                }
            }
        }

        // Process audio when silence is detected
        function processAudio() {
            if (isProcessing) return;

            isProcessing = true;
            statusText.textContent = "Processing audio...";
            log("Silence detected - processing audio");

            // Send a special message to indicate end of speech
            if (socket && socket.readyState === WebSocket.OPEN) {
                socket.send(JSON.stringify({
                    type: "end_of_speech"
                }));
            }

            // Keep recording but stop sending audio while processing
            silenceDetectionActive = false;

            // Reset after a response or timeout
            processingTimeout = setTimeout(() => {
                isProcessing = false;
                silenceDetectionActive = true;
                statusText.textContent = "Speak now...";
            }, 10000); // 10 second timeout in case no response
        }

        // Restart recording after processing
        function restartListening() {
            if (processingTimeout) {
                clearTimeout(processingTimeout);
                processingTimeout = null;
            }

            isProcessing = false;
            silenceDetectionActive = true;
            statusText.textContent = "Speak now...";
        }

        // Stop recording
        function stopRecording() {
            if (mediaRecorder) {
                mediaRecorder.stop();
                mediaRecorder = null;
            }

            isRecording = false;
            silenceDetectionActive = false;

            if (processingTimeout) {
                clearTimeout(processingTimeout);
                processingTimeout = null;
            }

            recordButton.textContent = 'Start Recording';
            statusIndicator.textContent = 'âšª Press Start Recording to begin';
            statusText.textContent = "Silence detection ready";
            volumeLevel.style.width = '0%';
            log('Recording stopped');
        }

        // Convert Float32Array to Int16Array for server
        function convertFloat32ToInt16(buffer) {
            const l = buffer.length;
            const buf = new Int16Array(l);

            for (let i = 0; i < l; i++) {
                buf[i] = Math.min(1, Math.max(-1, buffer[i])) * 0x7FFF;
            }

            return buf.buffer;
        }

        // Add audio to the queue and process queue
        function queueAudio(audioBuffer) {
            audioQueue.push(audioBuffer);
            // Start processing the queue if not already playing
            if (!isPlayingAudio) {
                processAudioQueue();
            }
        }

        // Process audio queue sequentially
        async function processAudioQueue() {
            if (audioQueue.length === 0) {
                isPlayingAudio = false;
                return;
            }

            isPlayingAudio = true;
            const nextAudio = audioQueue.shift();

            try {
                await playAudioAndWait(nextAudio);
            } catch (error) {
                console.error("Error playing audio:", error);
            }

            // Continue with next audio in queue
            processAudioQueue();
        }

        // Play a single audio buffer and return a promise that resolves when finished
        async function playAudioAndWait(audioBuffer) {
            return new Promise((resolve) => {
                if (!audioContext) {
                    // Create AudioContext if it doesn't exist
                    const AudioContextClass = window.AudioContext || window.webkitAudioContext;
                    audioContext = new AudioContextClass({
                        sampleRate: 24000
                    });
                }

                const audioData = new Int16Array(audioBuffer);
                const floatData = new Float32Array(audioData.length);

                // Convert Int16 to Float32
                for (let i = 0; i < audioData.length; i++) {
                    floatData[i] = audioData[i] / 0x7FFF;
                }

                // Create a new buffer with the audio data
                const buffer = audioContext.createBuffer(1, floatData.length, 24000);
                buffer.getChannelData(0).set(floatData);

                // Create and play a new source
                const source = audioContext.createBufferSource();
                source.buffer = buffer;
                source.connect(audioContext.destination);

                // Handle completion
                source.onended = () => {
                    resolve();
                };

                // Handle very short buffers that might not trigger onended
                const duration = buffer.duration * 1000; // ms
                if (duration < 50) {  // If buffer is very short
                    setTimeout(resolve, Math.max(50, duration + 10));
                }

                // Start playing
                source.start();

                // Fallback timeout in case onended doesn't fire
                setTimeout(resolve, Math.max(3000, buffer.duration * 1000 + 500));
            });
        }

        // Replace the old playAudio function
        async function playAudio(audioBuffer) {
            queueAudio(audioBuffer);
        }

        // Initialize
        document.addEventListener('DOMContentLoaded', function () {
            if (checkBrowserSupport()) {
                connectWebSocket();
            } else {
                recordButton.disabled = true;
            }

            // Add keyboard shortcuts
            document.addEventListener('keydown', function (event) {
                if (event.key === 'r' || event.key === 'R') {
                    recordButton.click();
                }
            });
        });

        // Handle page unload
        window.addEventListener('beforeunload', function () {
            if (isRecording) {
                stopRecording();
            }
            if (socket) {
                socket.close();
            }
        });
    </script>
</body>

</html>